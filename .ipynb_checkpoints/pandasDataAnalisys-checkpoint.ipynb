{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Aby dane były jakkolwiek poprawnie przewidywane, niezbędne będzie pobranie wartości akcji sprzed minimum dwóchch lat!\\\n",
    "importowanie niezbędnych bibliotek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas_datareader.data as pdr\n",
    "from pandas_datareader._utils import RemoteDataError\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['font.size'] = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "utworzenie zmiennych typu datetime do przechowania zakresu czasu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "date = [2021, 1, 1]  # podanie przez uĹĽytkownika daty od ktĂłrej majÄ… byÄ‡ pobrane dane (rok, miesiÄ…c, dzieĹ„)\n",
    "end_time = dt.datetime.now()  # aktualny czas\n",
    "start_time = dt.datetime(date[0], date[1], date[2])  # czas poczÄ…tkowy\n",
    "time_data = (start_time, end_time,\n",
    "             start_time - end_time)  # krotka przechowujÄ…ca informacje o czasie (czas poczÄ…tkowy, aktualny czas, roznica)\n",
    "json_file_path = \"config.json\"  # Ĺ›cieĹĽka do pliku konfiguracyjnego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "zaĹ‚adowanie pliku JSON do dict'a config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(json_file_path) as json_file:\n",
    "    config = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "moĹĽliwe jest teĹĽ odczytanie z pliku z wykorzystaniem przygotowanej funkcji get_stock_data_from_file(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "funkcja wykorzystujÄ…ca biblioteki tensorflow do utworzenia modelu ML oraz przewidywanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_stock_moves_ML(stock_input_array):\n",
    "    try:\n",
    "        # moĹĽliwe jest przekazanie tylko jednej akcji na raz!!!\n",
    "        data = stock_input_array.filter(['Close'])  # filtrowanie data frame w celu uzyskania tylko kolumny Close\n",
    "        dataset = data.values  # konwersja na np.array\n",
    "        # wykorzystanie 80% danych do uczenia maszynowego (nie ma sensu wiÄ™cej)\n",
    "        training_data_len = math.ceil(len(dataset) * .8)\n",
    "        # normalizacja danych z wykorzystaniem MinMaxScaler\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_data = scaler.fit_transform(dataset)\n",
    "        # przygotowanie danych do trenowania modelu\n",
    "        train_data = scaled_data[0:training_data_len, :]\n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        for i in range(60, len(train_data)):\n",
    "            x_train.append(train_data[i - 60:i, 0])\n",
    "            y_train.append(train_data[i, 0])\n",
    "        # konwersja x_train oraz y_train na np\n",
    "        x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "        # przygotowanie macierzy trĂłjwymiarowej (wymagane przez silnik neuronowy LSTM)\n",
    "        print(f\"Aktualna wielkoĹ›Ä‡ danych treningowych wynosi {x_train.shape[0]}x{x_train.shape[1]}\")\n",
    "        x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "        # budowanie modelu\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "        model.add(LSTM(50, return_sequences=False))\n",
    "        model.add(Dense(25))\n",
    "        model.add(Dense(1))\n",
    "        # kompilowanie modelu\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "        # trenowanie modelu\n",
    "        model.fit(x_train, y_train, batch_size=1, epochs=15)\n",
    "        model_output_path = config['model_path']\n",
    "        model.save(model_output_path, save_format='tf')\n",
    "        # utworzenie danych do testowania\n",
    "        test_data = scaled_data[training_data_len - 60:, :]\n",
    "        # utworzenie x_test oraz y_test\n",
    "        x_test = []\n",
    "        y_test = dataset[training_data_len:, :]\n",
    "        for i in range(60, len(test_data)):\n",
    "            x_test.append(test_data[i - 60:i, 0])\n",
    "        # konwersja x_test na np\n",
    "        x_test = np.array(x_test)\n",
    "        # przygotowanie macierzy trĂłjwymiarowej (wymagane przez silnik neuronowy LSTM)\n",
    "        x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "        # przewidywanie\n",
    "        predictions = model.predict(x_test)\n",
    "        predictions = scaler.inverse_transform(predictions)\n",
    "        # uzyskiwanie RMSE - Root Mean Square Error (jest standardowym sposobem pomiaru bĹ‚Ä™du modelu w przewidywaniu danych iloĹ›ciowych)\n",
    "        RMSE = np.sqrt(np.mean(predictions - y_test) ** 2)\n",
    "        print(f\"WspĂłĹ‚czynnik RMSE wynosi: {RMSE}\")\n",
    "        train = data[:training_data_len]\n",
    "        valid = data[training_data_len:]\n",
    "        valid['Predictions'] = predictions\n",
    "        output = (train, valid)\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        print(f'Exception message: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "funkcja wizualizujÄ…ca przewidywane dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_predicted_data(train, valid, save_to_files, count, current_stock_name):\n",
    "    try:\n",
    "        plt.figure()\n",
    "        plt.title(current_stock_name + \" ML Predicitions\")\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Close price')\n",
    "        plt.plot(train['Close'])\n",
    "        plt.plot(valid[['Close', 'Predictions']])\n",
    "        plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')\n",
    "        if save_to_files:\n",
    "            file_name = \"graph\" + str(count) + \".png\"\n",
    "            plt.savefig(file_name)\n",
    "            count += 1\n",
    "        return count\n",
    "    except Exception as e:\n",
    "        print(f'Exception message: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "pobieranie danych z wykorzystaniem API z Yahoo Finances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_from_yahoo(stock_input_array):\n",
    "    try:\n",
    "        stock_data = pdr.get_data_yahoo(stock_input_array, start_time, end_time)\n",
    "        return stock_data\n",
    "    except RemoteDataError as e:\n",
    "        file_path_temp = config['stockFilePath']\n",
    "        print(f'No data found for {file_path_temp}. Exception message: {e}')\n",
    "        print(f\"Check your internet connection or firewall settings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "pobieranie danych z pliku txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_stock_data_from_file(file_path):\n",
    "    try:\n",
    "        lines_object = open(file_path, \"r\")\n",
    "        lines = lines_object.read().splitlines()\n",
    "        lines_object.close()\n",
    "        return lines\n",
    "    except RemoteDataError as e:\n",
    "        print(f'An error occured while trying to read {file_path}. Error message: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "wizualizacja wszystkich akcji na jednym wykresie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_graphs(input_data_frame, save_to_files, count):\n",
    "    try:\n",
    "        input_data_frame = input_data_frame.Close\n",
    "        input_data_frame.plot()\n",
    "        if save_to_files:\n",
    "            file_name = \"graph\" + str(count) + \".png\"\n",
    "            plt.savefig(file_name)\n",
    "            count += 1\n",
    "        input_data_frame.plot.box()\n",
    "        if save_to_files:\n",
    "            file_name = \"graph\" + str(count) + \".png\"\n",
    "            plt.savefig(file_name)\n",
    "            count += 1\n",
    "        input_data_frame.plot.area(stacked=False)\n",
    "        if save_to_files:\n",
    "            file_name = \"graph\" + str(count) + \".png\"\n",
    "            plt.savefig(file_name)\n",
    "            count += 1\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "        return count\n",
    "    except Exception as e:\n",
    "        print(f'Exception message: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # pobieranie danych z Yahoo Finances\n",
    "    stocks = get_stock_data_from_file(config['stockFilePath'])\n",
    "    counter = 0\n",
    "    data_frame = get_data_from_yahoo(stocks)\n",
    "    # Przygotowywanie wizualizacji pobranych danych\n",
    "    counter = show_graphs(data_frame, bool(config['performGraphSave']), counter)\n",
    "    for stock in stocks:\n",
    "        data_frame = get_data_from_yahoo(stock)\n",
    "        # Wizualizacja przewidywanego zachowania gieĹ‚dy na 60 dni do przodu\n",
    "        train, valid = predict_stock_moves_ML(data_frame)\n",
    "        counter = visualize_predicted_data(train, valid, bool(config['performGraphSave']), counter, stock)\n",
    "        # WyĹ›wietlenie wykresĂłw\n",
    "        plt.show()\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
